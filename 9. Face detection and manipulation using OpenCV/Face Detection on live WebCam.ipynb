{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc704735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f4fad",
   "metadata": {},
   "source": [
    "## 1. Detecting Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd29a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 3)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv.rectangle(img, (x,y),(x+w,y+h), (0,180,0), 2)   \n",
    "\n",
    "    cv.imshow('Original', img)\n",
    "    \n",
    "    if(cv.waitKey(10) == 27):\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00790afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 67, 192, 192)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddafdbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHK~1\\AppData\\Local\\Temp/ipykernel_25380/2833090475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frames'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cropped-Frames'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "        \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv.rectangle(img, (x,y), (x+w,y+h), 3)\n",
    "        face = img[x:x+w, y:y+h]\n",
    "    \n",
    "    cv.imshow('Frames', img)\n",
    "    cv.imshow('Cropped-Frames', face)\n",
    "    \n",
    "    key = cv.waitKey(30)\n",
    "    \n",
    "    if key == 27:\n",
    "        cam.release\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d99dbab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7d220",
   "metadata": {},
   "source": [
    "## 2. Crop the Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc377ea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HARSHK~1\\AppData\\Local\\Temp/ipykernel_10644/1701600273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original'\u001b[0m    \u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cropped_Face'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "    \n",
    "    if(len(faces) >= 1):\n",
    "        x = f[0]\n",
    "        y = f[1]\n",
    "        w = f[2]\n",
    "        h = f[3]\n",
    "    \n",
    "        cv.rectangle(img, (x,y),(x+w,y+h) , (0,180,0), 2)   \n",
    "        face = img[y:y+h, x:x+w]\n",
    "#         face = cv.resize(face, (256,256))\n",
    "        \n",
    "    cv.imshow('Original'    , img)\n",
    "    cv.imshow('Cropped_Face', face)\n",
    "    \n",
    "    if(cv.waitKey(10) == 27):\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b2f7b",
   "metadata": {},
   "source": [
    "## 3. Blur the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e75ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "    \n",
    "    if(len(faces) >= 1):\n",
    "        x = f[0]\n",
    "        y = f[1]\n",
    "        w = f[2]\n",
    "        h = f[3]\n",
    "    \n",
    "        cv.rectangle(img, (x,y),(x+w,y+h) , (0,180,0), 2)   \n",
    "        face = img[y:y+h, x:x+w]                             # Getting the face area from feed\n",
    "        face = cv.blur(face, (10,10))                        # Applying blur on face\n",
    "        img[y:y+h, x:x+w] = face                             # Apply blure face on video feed\n",
    "        \n",
    "    cv.imshow('Original'    , img)\n",
    "#     cv.imshow('Cropped_Face', face)\n",
    "    \n",
    "    if(cv.waitKey(10) == 27):\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0ea20",
   "metadata": {},
   "source": [
    "## 4.1 Applying Square at the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a499bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "    \n",
    "    x = f[0]\n",
    "    y = f[1]\n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "        \n",
    "    face = img[y:y+h, x:x+w]                             # Getting the face area from feed\n",
    "    black = np.zeros((face.shape), dtype = int)\n",
    "    img[y:y+h, x:x+w] = black                            \n",
    "        \n",
    "    cv.imshow('Original'    , img)\n",
    "    \n",
    "    if(cv.waitKey(10) == 27):\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89d08e",
   "metadata": {},
   "source": [
    "## 4.2 Applying Circle at the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4cc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    x = f[0]\n",
    "    y = f[1]\n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "    \n",
    "    circle_x = x + int(w/2)\n",
    "    circle_y = y + int(h/2)\n",
    "    \n",
    "    cv.circle(img, (circle_x, circle_y), int(w/1.5), (110,180,68,0.5), -1)\n",
    "    \n",
    "    cv.imshow('Original'    , img)\n",
    "    \n",
    "    if(cv.waitKey(10) == 27):\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90251ec",
   "metadata": {},
   "source": [
    "## 5. Extracting face from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('image_1.jpg')\n",
    "faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "\n",
    "def save(frame, folder_name):\n",
    "    name_img = len(os.listdir(folder_name)) + 1\n",
    "    name_img = folder_name + '/IMG' + str(name_img) + '.png'\n",
    "    cv.imwrite(name_img, frame)\n",
    "    print(name_img, 'is exported.')\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    cv.imshow('Faces', face)\n",
    "    \n",
    "    if cv.waitKey(0) == 13:\n",
    "        save(face, 'People')\n",
    "    elif cv.waitKey(0) == 127:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5730a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ab489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
